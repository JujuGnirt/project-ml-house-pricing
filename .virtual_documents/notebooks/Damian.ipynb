import pandas as pd

# Always reload the data to avoid stale state
df = pd.read_csv("/Users/dejmen/desktop/ironhack/week7/day1/project-ml-house-pricing/data/raw/data_house.csv") 

df.head()


columns_to_drop = ["yr_renovated", "date", "long", "lat", "id"]

unnamed_cols = [col for col in df.columns if 'unnamed' in col.lower()]
columns_to_drop.extend(unnamed_cols)

df_cleaned = df.drop(columns=columns_to_drop)
df_cleaned


import matplotlib.pyplot as plt
import seaborn as sns

null_values = df_cleaned.isnull().sum()
null_values


# Check data types
data_types = df_cleaned.dtypes
data_types


#HINTS FROM IGNACIO:

# Step 1: Compute mean price per ZIP code and sort by the mean price
mean_price_per_zip = df_cleaned.groupby('zipcode')['price'].mean()

# Step 2: Identify the cheapest ZIP code's mean price
min_price = mean_price_per_zip.min()

# Step 3: Create a ZIP code to price ratio mapping
zip_ratio_map = (mean_price_per_zip / min_price).to_dict()

# Step 4: Replace ZIP codes with their price ratio
df_cleaned['zipcode'] = df_cleaned['zipcode'].map(zip_ratio_map)

df_cleaned[['zipcode']].head()



df_cleaned.head()


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Use your actual DataFrame name, like df_cleaned or df_fe
correlation_matrix = df_cleaned.corr(numeric_only=True)

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Features Correlation to Price")
plt.show()



# Plot feature distributions (excluding 'price')
plt.figure(figsize=(16, 12))
df_cleaned.drop('price', axis=1).hist(bins=30, figsize=(16, 12))
plt.suptitle('Feature Distributions', fontsize=20)
plt.tight_layout()
plt.show()

# Correlation with target variable 'price'
correlation_matrix = df_cleaned.corr()
correlation_with_price = correlation_matrix['price'].sort_values(ascending=False)
correlation_with_price


from sklearn.model_selection import train_test_split

# Define X (features) and y (target)
X = df_cleaned.drop(columns='price') 
y = df_cleaned['price']             

# Split into train and test sets 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# the shape of splits
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)


# Standardization

from sklearn.preprocessing import StandardScaler

#Initialize the scaler
scaler = StandardScaler()

#Fit the scaler ONLY on training data
X_train_scaled = scaler.fit_transform(X_train)

# Transform both training and test sets
X_test_scaled = scaler.transform(X_test)
X_train_scaled
X_test_scaled


# Normalization

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_train_scaled
X_test_scaled


from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score

# Initialize the model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the model on the scaled training data
rf_model.fit(X_train_scaled, y_train)

# Predict on the test data
y_pred = rf_model.predict(X_test_scaled)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Absolute Error (MAE):", mae)
print("R^2 Score:", r2)



# MAE tells you the average absolute difference between predicted and actual prices.
# RÂ² Score tells how well the model explains the variance in house prices:
# 1.0 = perfect
# 0 = no predictive power


# Visualize predictions
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("Random Forest: Actual vs Predicted Prices")
plt.grid(True)
plt.tight_layout()
plt.show()

mae, r2




